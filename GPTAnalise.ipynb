{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Importe de Bibiliotecas e definição de mêtodos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def shuffle(a, b, ratio):\n",
        "    c = list(zip(a, b))\n",
        "    random.shuffle(c)\n",
        "    data, target = zip(*c)\n",
        "    test:int = int(len(iris.data)*ratio)\n",
        "    X_train = data[0:test]\n",
        "    X_test = data[test:]\n",
        "    Y_train = target[0:test]\n",
        "    Y_test = target[test:]\n",
        "    return X_train, X_test, Y_train, Y_test\n",
        "\n",
        "def metricas(Y_test, predictions):\n",
        "    confusion_matrix = metrics.confusion_matrix(Y_test, predictions)\n",
        "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [0, 1, 2])\n",
        "    cm_display.plot()\n",
        "    plt.show()\n",
        "    accuracy = metrics.accuracy_score(Y_test, predictions, normalize= True)\n",
        "    recall = metrics.recall_score(Y_test, predictions, average=None)\n",
        "    precision = metrics.precision_score(Y_test, predictions, average=None)\n",
        "    f1 = metrics.f1_score(Y_test, predictions, average=None)\n",
        "    print(\"Acuracia:\", accuracy)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"f1 score:\", f1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analisando implementações de _kNN_, _Naive Bayes_ e _Árvores de Decisão_ pelo ChatGPT\n",
        "### Lucas Salbego, Gabriel Moszkowicz\n",
        "\n",
        "Neste trabalho, queremos instruir o ChatGPT a gerar implementações _do zero_ de três algoritmos de Machine Learning vistos em aula: _kNN_, _Naive Bayes_ e _Árvores de Decisão_. Temos o intuito de analisar a qualidade não só das implementações, mas também dos resultados do ChatGPT ao considerar os nossos prompts.\n",
        "\n",
        "Estaremos interagindo com o modelo em inglês, e a linguagem escolhida será Python.\n",
        "\n",
        "## kNN\n",
        "\n",
        "A princípio, vamos começar com o prompt mais direto e ver como o ChatGPT se comporta:\n",
        "\n",
        "_Prompt: Implement a kNN Model in Python from scratch_\n",
        "\n",
        "_..._\n",
        "\n",
        "_ChatGPT: Sure, here's a basic implementation of the k-Nearest Neighbors (kNN) algorithm in Python from scratch:_\n",
        "\n",
        "```python\n",
        "import numpy as np\n",
        "\n",
        "class KNN:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for x in X:\n",
        "            distances = []\n",
        "            for i in range(len(self.X_train)):\n",
        "                distance = np.sqrt(np.sum(np.square(x - self.X_train[i])))\n",
        "                distances.append((distance, self.y_train[i]))\n",
        "            distances.sort(key=lambda x: x[0])\n",
        "            neighbors = distances[:self.k]\n",
        "            class_votes = {}\n",
        "            for neighbor in neighbors:\n",
        "                if neighbor[1] in class_votes:\n",
        "                    class_votes[neighbor[1]] += 1\n",
        "                else:\n",
        "                    class_votes[neighbor[1]] = 1\n",
        "            sorted_votes = sorted(class_votes.items(), key=lambda x: x[1], reverse=True)\n",
        "            predictions.append(sorted_votes[0][0])\n",
        "        return predictions\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    X_train = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
        "    y_train = np.array([0, 0, 1, 1])\n",
        "\n",
        "    knn = KNN(k=3)\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    X_test = np.array([[1, 1], [2, 2]])\n",
        "    predictions = knn.predict(X_test)\n",
        "    print(\"Predictions:\", predictions)\n",
        "\n",
        "```\n",
        "\n",
        "_ChatGPT: This code defines a KNN class with fit and predict methods. The fit method is used to train the model with training data, and the predict method is used to make predictions on new data points. The distance metric used here is Euclidean distance, and the class label of the majority of the k nearest neighbors is chosen as the prediction._\n",
        "\n",
        "O código funciona sem muitas alterações, e pode ser executado a seguir:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class KNN:\n",
        "    def __init__(self, k=3):\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for x in X:\n",
        "            distances = []\n",
        "            for i in range(len(self.X_train)):\n",
        "                distance = np.sqrt(np.sum(np.square(x - self.X_train[i])))\n",
        "                distances.append((distance, self.y_train[i]))\n",
        "            distances.sort(key=lambda x: x[0])\n",
        "            neighbors = distances[:self.k]\n",
        "            class_votes = {}\n",
        "            for neighbor in neighbors:\n",
        "                if neighbor[1] in class_votes:\n",
        "                    class_votes[neighbor[1]] += 1\n",
        "                else:\n",
        "                    class_votes[neighbor[1]] = 1\n",
        "            sorted_votes = sorted(class_votes.items(), key=lambda x: x[1], reverse=True)\n",
        "            predictions.append(sorted_votes[0][0])\n",
        "        return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pontos a Fracos:\n",
        "*  Cálculo de distâncias não é otimizado e roda em O(N^2).\n",
        "*  Apenas a distância euclidiana é disponibilizada.\n",
        "\n",
        "Pontos Fortes:\n",
        "*  Código roda.\n",
        "*  K é parametrizado."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Abaixo o modelo pode ser testado, sinta-se a vontade para alterar os parâmetros de entrada, como os conjuntos de treino e teste."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [2 3]\n",
            " [3 4]]\n",
            "[[4 5]]\n",
            "Predictions: [0, 1]\n"
          ]
        }
      ],
      "source": [
        "X_train = np.array([[1, 2], [2, 3], [3, 4], [4, 5]])\n",
        "y_train = np.array([0, 0, 1, 1])\n",
        "test = int(len(X_train)*0.75)\n",
        "a_treino = X_train[0: test]\n",
        "a_teste = X_train[test:]\n",
        "print(a_treino)\n",
        "print(a_teste)\n",
        "knn = KNN(k=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "X_test = np.array([[1, 1], [5, 6]])\n",
        "predictions = knn.predict(X_test)\n",
        "print(\"Predictions:\", predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Aplicação Dataset Iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "yabadeedabada\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Acuracia: 1.0\n",
            "Recall: [1. 1. 1.]\n",
            "Precision: [1. 1. 1.]\n",
            "f1 score: [1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "iris = datasets.load_iris()\n",
        "X_train, X_test, Y_train, Y_test = shuffle(iris.data, iris.target, 0.75)\n",
        "knn.fit(X_train, Y_train)\n",
        "predictions = knn.predict(X_test)\n",
        "metricas(Y_test, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Naive Bayes\n",
        "\n",
        "_Prompt: Implement the Naive Bayes algorithm in Python._\n",
        "\n",
        "_ChatGPT: This implementation assumes that the input features are binary, but you can adapt it for other types of features or preprocessing steps as needed_.\n",
        "```py\n",
        "import numpy as np\n",
        "\n",
        "class NaiveBayes:\n",
        "    def __init__(self):\n",
        "        self.prior = None\n",
        "        self.likelihood = None\n",
        "        self.classes = None\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.classes = np.unique(y)\n",
        "        n_classes = len(self.classes)\n",
        "        \n",
        "        # Initialize prior probabilities\n",
        "        self.prior = np.zeros(n_classes)\n",
        "        for i, c in enumerate(self.classes):\n",
        "            self.prior[i] = np.sum(y == c) / float(n_samples)\n",
        "        \n",
        "        # Initialize likelihood probabilities\n",
        "        self.likelihood = np.zeros((n_classes, n_features))\n",
        "        for i, c in enumerate(self.classes):\n",
        "            X_c = X[y == c]\n",
        "            self.likelihood[i] = (np.sum(X_c, axis=0) + 1) / (np.sum(X_c) + n_features)\n",
        "    \n",
        "    def predict(self, X):\n",
        "        posteriors = np.zeros((X.shape[0], len(self.classes)))\n",
        "        for i, c in enumerate(self.classes):\n",
        "            prior = np.log(self.prior[i])\n",
        "            likelihood = np.sum(np.log(self.likelihood[i, :]) * X, axis=1)\n",
        "            posteriors[:, i] = prior + likelihood\n",
        "        return np.argmax(posteriors, axis=1)\n",
        "\n",
        "# Example usage:\n",
        "X_train = np.array([[1, 1, 0], [1, 0, 0], [0, 1, 1], [0, 0, 1]])\n",
        "y_train = np.array([0, 1, 1, 0])\n",
        "X_test = np.array([[1, 0, 1], [0, 1, 0]])\n",
        "\n",
        "nb = NaiveBayes()\n",
        "nb.fit(X_train, y_train)\n",
        "predictions = nb.predict(X_test)\n",
        "print(\"Predictions:\", predictions)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions: [0 0]\n"
          ]
        }
      ],
      "source": [
        "class NaiveBayes:\n",
        "    def __init__(self):\n",
        "        self.prior = None\n",
        "        self.likelihood = None\n",
        "        self.classes = None\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.classes = np.unique(y)\n",
        "        n_classes = len(self.classes)\n",
        "        \n",
        "        # Initialize prior probabilities\n",
        "        self.prior = np.zeros(n_classes)\n",
        "        for i, c in enumerate(self.classes):\n",
        "            self.prior[i] = np.sum(y == c) / float(n_samples)\n",
        "        \n",
        "        # Initialize likelihood probabilities\n",
        "        self.likelihood = np.zeros((n_classes, n_features))\n",
        "        for i, c in enumerate(self.classes):\n",
        "            X_c = X[y == c]\n",
        "            self.likelihood[i] = (np.sum(X_c, axis=0) + 1) / (np.sum(X_c) + n_features)\n",
        "    \n",
        "    def predict(self, X):\n",
        "        posteriors = np.zeros((X.shape[0], len(self.classes)))\n",
        "        for i, c in enumerate(self.classes):\n",
        "            prior = np.log(self.prior[i])\n",
        "            likelihood = np.sum(np.log(self.likelihood[i, :]) * X, axis=1)\n",
        "            posteriors[:, i] = prior + likelihood\n",
        "        return np.argmax(posteriors, axis=1)\n",
        "\n",
        "# Example usage:\n",
        "X_train = np.array([[1, 1, 0], [1, 0, 0], [0, 1, 1], [0, 0, 1]])\n",
        "y_train = np.array([0, 1, 1, 0])\n",
        "X_test = np.array([[1, 0, 1], [0, 1, 0]])\n",
        "\n",
        "nb = NaiveBayes()\n",
        "nb.fit(X_train, y_train)\n",
        "predictions = nb.predict(X_test)\n",
        "print(\"Predictions:\", predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Árvore de Decisão\n",
        "_Prompt: Implement a decision tree prediction algorithm in python._\n",
        "\n",
        "_ChatGPT: Implementing a decision tree prediction algorithm from scratch can be quite complex due to its intricacies in splitting, pruning, and handling categorical and numerical data. Let's outline a basic version of the decision tree algorithm in Python. We'll focus on a simplified version of the algorithm called the CART (Classification and Regression Trees), which is commonly used for classification tasks._\n",
        "\n",
        "```py\n",
        "class Node:\n",
        "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
        "        self.feature_index = feature_index  # Index of the feature to split on\n",
        "        self.threshold = threshold  # Threshold value for the split\n",
        "        self.left = left  # Left child node\n",
        "        self.right = right  # Right child node\n",
        "        self.value = value  # Value if the node is a leaf node\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.n_classes_ = len(np.unique(y))\n",
        "        self.n_features_ = X.shape[1]\n",
        "        self.tree_ = self._grow_tree(X, y)\n",
        "\n",
        "    def _grow_tree(self, X, y, depth=0):\n",
        "        n_samples, n_features = X.shape\n",
        "        n_labels = len(np.unique(y))\n",
        "\n",
        "        # Stopping criteria\n",
        "        if (self.max_depth is not None and depth >= self.max_depth) or n_labels == 1:\n",
        "            leaf_value = np.bincount(y).argmax()\n",
        "            return Node(value=leaf_value)\n",
        "\n",
        "        # Find the best split\n",
        "        best_index, best_threshold = self._find_best_split(X, y)\n",
        "\n",
        "        if best_index is None:\n",
        "            leaf_value = np.bincount(y).argmax()\n",
        "            return Node(value=leaf_value)\n",
        "\n",
        "        # Split the dataset\n",
        "        left_indices = X[:, best_index] < best_threshold\n",
        "        X_left, y_left = X[left_indices], y[left_indices]\n",
        "        X_right, y_right = X[~left_indices], y[~left_indices]\n",
        "\n",
        "        # Recursive call to grow left and right child nodes\n",
        "        left = self._grow_tree(X_left, y_left, depth + 1)\n",
        "        right = self._grow_tree(X_right, y_right, depth + 1)\n",
        "\n",
        "        return Node(feature_index=best_index, threshold=best_threshold, left=left, right=right)\n",
        "\n",
        "    def _find_best_split(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        best_gini = float('inf')\n",
        "        best_index, best_threshold = None, None\n",
        "\n",
        "        for feature_index in range(n_features):\n",
        "            thresholds = np.unique(X[:, feature_index])\n",
        "            for threshold in thresholds:\n",
        "                left_indices = X[:, feature_index] < threshold\n",
        "                gini = self._gini_impurity(y[left_indices], y[~left_indices])\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_index = feature_index\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        return best_index, best_threshold\n",
        "\n",
        "    def _gini_impurity(self, left_labels, right_labels):\n",
        "        n_left, n_right = len(left_labels), len(right_labels)\n",
        "        n_total = n_left + n_right\n",
        "\n",
        "        gini_left = 1.0 - sum((np.sum(left_labels == c) / n_left) ** 2 for c in range(self.n_classes_))\n",
        "        gini_right = 1.0 - sum((np.sum(right_labels == c) / n_right) ** 2 for c in range(self.n_classes_))\n",
        "\n",
        "        gini = (n_left / n_total) * gini_left + (n_right / n_total) * gini_right\n",
        "        return gini\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_tree(x, self.tree_) for x in X])\n",
        "\n",
        "    def _predict_tree(self, x, node):\n",
        "        if node.value is not None:\n",
        "            return node.value\n",
        "\n",
        "        if x[node.feature_index] < node.threshold:\n",
        "            return self._predict_tree(x, node.left)\n",
        "        else:\n",
        "            return self._predict_tree(x, node.right)\n",
        "\n",
        "```\n",
        "\n",
        "_ChatGPT: This is a simplified version of a decision tree algorithm in Python. Real-world implementations would require additional optimizations and handling of various scenarios, such as handling missing values, pruning, and dealing with categorical variables._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Node:\n",
        "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, value=None):\n",
        "        self.feature_index = feature_index  # Index of the feature to split on\n",
        "        self.threshold = threshold  # Threshold value for the split\n",
        "        self.left = left  # Left child node\n",
        "        self.right = right  # Right child node\n",
        "        self.value = value  # Value if the node is a leaf node\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.n_classes_ = len(np.unique(y))\n",
        "        self.n_features_ = X.shape[1]\n",
        "        self.tree_ = self._grow_tree(X, y)\n",
        "\n",
        "    def _grow_tree(self, X, y, depth=0):\n",
        "        n_samples, n_features = X.shape\n",
        "        n_labels = len(np.unique(y))\n",
        "\n",
        "        # Stopping criteria\n",
        "        if (self.max_depth is not None and depth >= self.max_depth) or n_labels == 1:\n",
        "            leaf_value = np.bincount(y).argmax()\n",
        "            return Node(value=leaf_value)\n",
        "\n",
        "        # Find the best split\n",
        "        best_index, best_threshold = self._find_best_split(X, y)\n",
        "\n",
        "        if best_index is None:\n",
        "            leaf_value = np.bincount(y).argmax()\n",
        "            return Node(value=leaf_value)\n",
        "\n",
        "        # Split the dataset\n",
        "        left_indices = X[:, best_index] < best_threshold\n",
        "        X_left, y_left = X[left_indices], y[left_indices]\n",
        "        X_right, y_right = X[~left_indices], y[~left_indices]\n",
        "\n",
        "        # Recursive call to grow left and right child nodes\n",
        "        left = self._grow_tree(X_left, y_left, depth + 1)\n",
        "        right = self._grow_tree(X_right, y_right, depth + 1)\n",
        "\n",
        "        return Node(feature_index=best_index, threshold=best_threshold, left=left, right=right)\n",
        "\n",
        "    def _find_best_split(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        best_gini = float('inf')\n",
        "        best_index, best_threshold = None, None\n",
        "\n",
        "        for feature_index in range(n_features):\n",
        "            thresholds = np.unique(X[:, feature_index])\n",
        "            for threshold in thresholds:\n",
        "                left_indices = X[:, feature_index] < threshold\n",
        "                gini = self._gini_impurity(y[left_indices], y[~left_indices])\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_index = feature_index\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        return best_index, best_threshold\n",
        "\n",
        "    def _gini_impurity(self, left_labels, right_labels):\n",
        "        n_left, n_right = len(left_labels), len(right_labels)\n",
        "        n_total = n_left + n_right\n",
        "\n",
        "        gini_left = 1.0 - sum((np.sum(left_labels == c) / n_left) ** 2 for c in range(self.n_classes_))\n",
        "        gini_right = 1.0 - sum((np.sum(right_labels == c) / n_right) ** 2 for c in range(self.n_classes_))\n",
        "\n",
        "        gini = (n_left / n_total) * gini_left + (n_right / n_total) * gini_right\n",
        "        return gini\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_tree(x, self.tree_) for x in X])\n",
        "\n",
        "    def _predict_tree(self, x, node):\n",
        "        if node.value is not None:\n",
        "            return node.value\n",
        "\n",
        "        if x[node.feature_index] < node.threshold:\n",
        "            return self._predict_tree(x, node.left)\n",
        "        else:\n",
        "            return self._predict_tree(x, node.right)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Análise\n",
        "* Construção da Árvore é Top Down recursiva.\n",
        "* Implementa a medida de imperuza Gini.\n",
        "\n",
        "#### Pontos Fracos\n",
        "\n",
        "#### Pontos Fortes"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
